EventId,EventTemplate,Occurrences
18bf7240,DB_HOME: /databricks,1
1c257a9c,========== driver starting up ==========,1
4655b4ae,Java: Private Build 1.8.0_232,1
028867b6,OS: Linux/amd64 4.4.0-1102-aws,1
d74d6910,CWD: /databricks/driver,1
ecab9817,"Mem: Max: 4.8G loaded GCs: PS Scavenge, PS MarkSweep",1
ad84d2dd,Logging multibyte characters: âœ“,1
4690b9f6,'publicFile' appender in root logger: class com.databricks.logging.RedactionRollingFileAppender,1
38f76352,<*> appender in root logger: class <*>,2
4fce4bb4,== Modules:,1
e662b3c6,Starting prometheus metrics log export timer,1
8cd83268,Universe Git Hash: 687e04cafbfe88e512c6aea9e4f53a2c4e1d5689,1
20b49405,Spark Git Hash: 428199fa1bdaea59715ade6e7d4d6bb5a11c388d,1
712bd1a0,"Missing tag isolation client: java.util.NoSuchElementException: key not found: TagDefinition(clientType,The client type for a request, used for isolating resources for the request.)",1
b14b4ca1,Creating throwaway interpreter,1
e28cf8b0,Customize spark config according to file /tmp/custom-spark.conf,3
365b761d,"Internal internal metastore configured (config=DbMetastoreConfig{host=devtierprod1-db.caj77bnxuhme.us-west-2.rds.amazonaws.com, port=3306, dbName=organization823618267676840, user=YbAhhCtN6Tgu0BzS})",1
927bc97a,metastore-monitor - Starting...,3
5b7e5d94,metastore-monitor - <*> completed.,6
d3a0de76,Creating the driver context,1
1a09080b,Class Server Dir: /local_disk0/tmp/repl/spark-3281211262966016233-8fe57c53-b822-4434-871c-c263ce4408f3,1
d62e22a5,The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.,2
79466fcb,metastore-monitor - Shutdown initiated...,3
a68c364d,Metastore healthcheck successful (connection duration = <*> milliseconds),3
fc4b7056,Running Spark version 2.4.4,1
d123ccb4,"Detected deprecated memory fraction settings: [spark.storage.memoryFraction, spark.shuffle.memoryFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).",1
a7c31293,Submitted application: Databricks Shell,1
b810e215,Changing <*> acls to: root,2
66c1cc9e,Changing <*> acls groups to:,2
f37a5454,SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(),1
f5a68e94,Successfully started service <*> on port <*>,3
657cfe01,Registering MapOutputTracker,1
d353d6f7,Registering BlockManagerMaster,1
add369a7,Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information,1
f8f0a311,BlockManagerMasterEndpoint up,1
2e39369f,Created local directory at /local_disk0/blockmgr-8d21e9b3-3221-4782-821f-fca3197f1480,1
fafeec11,MemoryStore started with capacity 2.5 GB,1
dc5b83ae,Registering OutputCommitCoordinator,1
6d9d4370,Spark configuration:,1
1d120ff3,Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.,1
1424647a,Logging initialized @7531ms,1
3a1b91d0,"jetty-9.3.27.v20190418, build timestamp: 2019-04-18T18:11:38Z, git hash: d3e249f86955d04bc646bb620905b7c1bc596a8d",4
c66d4456,Started @7697ms,1
4df8c34f,"Started ServerConnector@67e25252{HTTP/1.1,[http/1.1]}{10.172.228.50:42605}",1
00329def,"Started o.e.j.s.ServletContextHandler@55fee662{/jobs,null,AVAILABLE,@Spark}",1
479d08b6,"Started o.e.j.s.ServletContextHandler@309cedb6{/jobs/json,null,AVAILABLE,@Spark}",1
45c3a018,"Started o.e.j.s.ServletContextHandler@3b95a6db{/jobs/job,null,AVAILABLE,@Spark}",1
2079e744,"Started o.e.j.s.ServletContextHandler@2c9a6717{/jobs/job/json,null,AVAILABLE,@Spark}",1
d28dac24,"Started o.e.j.s.ServletContextHandler@7b3cde6f{/stages,null,AVAILABLE,@Spark}",1
eac877da,"Started o.e.j.s.ServletContextHandler@6d091cad{/stages/json,null,AVAILABLE,@Spark}",1
c8528545,"Started o.e.j.s.ServletContextHandler@7c663eaf{/stages/stage,null,AVAILABLE,@Spark}",1
37c56155,"Started o.e.j.s.ServletContextHandler@3ba0ae41{/stages/stage/json,null,AVAILABLE,@Spark}",1
abad6f2c,"Started o.e.j.s.ServletContextHandler@76fe6cdc{/stages/pool,null,AVAILABLE,@Spark}",1
03fb7f98,"Started o.e.j.s.ServletContextHandler@2ffb3aec{/stages/pool/json,null,AVAILABLE,@Spark}",1
f7c61d5b,"Started o.e.j.s.ServletContextHandler@786ff1cb{/storage,null,AVAILABLE,@Spark}",1
768a2155,"Started o.e.j.s.ServletContextHandler@46039a21{/storage/json,null,AVAILABLE,@Spark}",1
c69cc109,"Started o.e.j.s.ServletContextHandler@431e86b1{/storage/rdd,null,AVAILABLE,@Spark}",1
7ebb864e,"Started o.e.j.s.ServletContextHandler@35c4e864{/storage/rdd/json,null,AVAILABLE,@Spark}",1
ac704288,"Started o.e.j.s.ServletContextHandler@32a2a6be{/environment,null,AVAILABLE,@Spark}",1
d9ea710d,"Started o.e.j.s.ServletContextHandler@682af059{/environment/json,null,AVAILABLE,@Spark}",1
aab29aa7,"Started o.e.j.s.ServletContextHandler@5f36c8e3{/executors,null,AVAILABLE,@Spark}",1
aee761c3,"Started o.e.j.s.ServletContextHandler@4da39ca9{/executors/json,null,AVAILABLE,@Spark}",1
0ca7aef7,"Started o.e.j.s.ServletContextHandler@6a9344f5{/executors/threadDump,null,AVAILABLE,@Spark}",1
0749d11a,"Started o.e.j.s.ServletContextHandler@5584d9c6{/executors/threadDump/json,null,AVAILABLE,@Spark}",1
7455dc22,"Started o.e.j.s.ServletContextHandler@3c9c6245{/executors/heapHistogram,null,AVAILABLE,@Spark}",1
9256fd10,"Started o.e.j.s.ServletContextHandler@6d0be7ab{/executors/heapHistogram/json,null,AVAILABLE,@Spark}",1
454c99d7,"Started o.e.j.s.ServletContextHandler@1d4fb213{/static,null,AVAILABLE,@Spark}",1
e29939b0,"Started o.e.j.s.ServletContextHandler@1668919e{/,null,AVAILABLE,@Spark}",1
38c81fe7,"Started o.e.j.s.ServletContextHandler@63300c4b{/api,null,AVAILABLE,@Spark}",1
3f089cdf,"Started o.e.j.s.ServletContextHandler@b67cc70{/jobs/job/kill,null,AVAILABLE,@Spark}",1
2f4d9d25,"Started o.e.j.s.ServletContextHandler@45c9b3{/stages/stage/kill,null,AVAILABLE,@Spark}",1
c4ab676f,"Bound SparkUI to 10.172.228.50, and started at http://10.172.228.50:42605",1
26d69558,"Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.",1
d7be2f12,"Created default pool: default, schedulingMode: FIFO, minShare: 0, weight: 1",1
9b7c20e2,Starting executor ID driver on host localhost,1
bae0caf2,Using REPL class URI: spark://10.172.228.50:34230/classes,1
958d481c,Task preemption enabled.,1
2e344772,Server created on 10.172.228.50:33830,1
aafe1779,Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy,1
b26d8498,"Registering BlockManager BlockManagerId(driver, 10.172.228.50, 33830, None)",1
754814e0,"Registering block manager 10.172.228.50:33830 with 2.5 GB RAM, BlockManagerId(driver, 10.172.228.50, 33830, None)",1
967da50a,"Registered BlockManager BlockManagerId(driver, 10.172.228.50, 33830, None)",1
8247b6ce,external shuffle service port = 4048,1
8adcd294,"Initialized BlockManager: BlockManagerId(driver, 10.172.228.50, 33830, None)",1
c6cb6c38,"Started o.e.j.s.ServletContextHandler@1039bfc4{/metrics/json,null,AVAILABLE,@Spark}",1
4e62be17,Initializing DBCEventLoggingListener,1
08411049,Logging events to eventlogs/3281211262966016233/eventlog,1
65e66212,Registered listener com.databricks.backend.daemon.driver.DBCEventLoggingListener,1
fe11ae85,Loading Spark Service RPC Server,1
2f38be19,Starting Spark Service RPC Server,1
bb3959d0,"Started ServerConnector@543d5863{HTTP/1.1,[http/1.1]}{0.0.0.0:15001}",1
8286b4f4,Started @9183ms,1
4558595b,Successfully registered spark metrics in Prometheus registry,1
804edc76,Successfully initialized SparkContext,1
2eaf7cc5,Initialized DBFS with DBFSV1 as the delegate.,1
6ade2511,Could not load DynamicJettyClientConf,1
00f8393c,"Creating new HttpClient with SSLContextFactory=None,maxRequestHeaderSize=65536, <*> idleTimeout=2 hours, useBlockingConnect: true",2
c4ab4fbf,Scheduler stats enabled.,1
af7e1aed,loading hive config file: file:/databricks/hive/conf/hive-site.xml,1
976cbf3b,Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('/user/hive/warehouse').,1
2295f829,Warehouse path is '/user/hive/warehouse'.,1
a404be4e,"Started o.e.j.s.ServletContextHandler@5b066c33{/SQL,null,AVAILABLE,@Spark}",1
74b02e22,"Started o.e.j.s.ServletContextHandler@62ea8931{/SQL/json,null,AVAILABLE,@Spark}",1
bda8c3ce,"Started o.e.j.s.ServletContextHandler@71166348{/SQL/execution,null,AVAILABLE,@Spark}",1
5f900836,"Started o.e.j.s.ServletContextHandler@6d874695{/SQL/execution/json,null,AVAILABLE,@Spark}",1
13f8d2c1,"Started o.e.j.s.ServletContextHandler@10ed037a{/static/sql,null,AVAILABLE,@Spark}",1
b1b51d81,"Started o.e.j.s.ServletContextHandler@150fc7a7{/storage/iocache,null,AVAILABLE,@Spark}",1
c9058e7c,"Started o.e.j.s.ServletContextHandler@55d8c2c4{/storage/iocache/json,null,AVAILABLE,@Spark}",1
6c28c815,Finished creating throwaway interpreter,1
931b701e,Registered StateStoreCoordinator endpoint,1
916787de,"Initializing execution hive, version 1.2.1",1
c513a2c4,<*> Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore,3
f97d2395,"ObjectStore, initialize called",4
187a75f5,Property <*> unknown - will be ignored,5
b90681cc,"Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes=""Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order""",2
5592bcff,"The class <*> is tagged as ""embedded-only"" so does not have its own datastore table.",9
e8fc0ba7,"Using direct SQL, underlying DB is DERBY",2
fee37921,Initialized ObjectStore,4
571c9214,Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0,1
c111d0d0,"Failed to get database default, returning NoSuchObjectException",1
36a330ca,Added <*> role in metastore,4
ba641907,"No user is added in admin role, since config is empty",2
494bd030,0: get_all_databases,1
a44f6d49,ugi=root ip=unknown-ip-addr cmd=get_all_databases,1
c2534b22,0: <*> db=default pat=*,3
a5ec3f8e,ugi=root ip=unknown-ip-addr <*> db=default pat=*,3
7984d8f5,Created HDFS directory: <*>,3
98458554,Created local directory: <*>,3
0337ff6b,Warehouse location for Hive client (version <*> is /user/hive/warehouse,2
d2718f89,Operation log root directory is created: /local_disk0/tmp/root/operation_logs,1
c40036b9,HiveServer2: Background operation thread pool size: 100,1
df8ad543,HiveServer2: Background operation thread wait queue size: 100,1
924bc959,HiveServer2: Background operation thread keepalive time: 10 seconds,1
b2e82aff,Service:OperationManager is <*>,2
4ca35cf6,Service:SessionManager is <*>,2
abd5fe09,Service: <*> is inited.,2
d000210a,Service:ThriftHttpCLIService is <*>,2
36671eb4,Service:CLIService is started.,1
af819f61,"Reading in results for query ""org.datanucleus.store.rdbms.query.SQLQuery@0"" since the connection used is closing",3
ef63b8b7,0: <*> default,10
1b7c4b8a,ugi=root ip=unknown-ip-addr <*> default,12
a70e3d9b,0: Shutting down the object store...,1
84c58f83,ugi=root ip=unknown-ip-addr cmd=Shutting down the object store...,1
32cf53be,0: Metastore shutdown complete.,1
27334525,ugi=root ip=unknown-ip-addr cmd=Metastore shutdown complete.,1
0f87fea4,Service:HiveServer2 is started.,1
58a7872f,"HTTP Server SSL: adding excluded protocols: [SSLv2, SSLv3]",1
890e00e5,"HTTP Server SSL: SslContextFactory.getExcludeProtocols = [SSL, SSLv2, SSLv2Hello, SSLv3]",1
72f9bd9d,"Started o.e.j.s.ServletContextHandler@263f6e96{/sqlserver,null,AVAILABLE,@Spark}",1
20041d0d,"Started o.e.j.s.ServletContextHandler@49741e80{/sqlserver/json,null,AVAILABLE,@Spark}",1
6d591719,"Started o.e.j.s.ServletContextHandler@dd3e1e3{/sqlserver/session,null,AVAILABLE,@Spark}",1
d2353d8b,"Started o.e.j.s.ServletContextHandler@2686a801{/sqlserver/session/json,null,AVAILABLE,@Spark}",1
1c71fa04,Library file for validation /databricks/.python-env/packages_to_validate.json does not exist,1
12de4bbb,Starting driver daemon...,1
725b6ac7,Message out thread ready,1
685a90bf,"Started ServerConnector@1a34f8e2{HTTP/1.1,[http/1.1]}{0.0.0.0:6061}",1
92f0caab,Started @22781ms,1
c7574caf,Driver daemon started.,1
75fd2b2c,"ServletContext@o.e.j.s.ServletContextHandler@77d00969{/,null,STARTING} has uncovered http methods for path: /*",1
be069e9a,"Started o.e.j.s.ServletContextHandler@77d00969{/,null,AVAILABLE}",1
20613e2e,"x509=X509@2f07e871(1,h=[databrickscloud.com],w=[]) for SslContextFactory@711ca071(file:///databricks/keys/jetty-ssl-driver-keystore.jks,null)",1
227c5dcf,"Started ServerConnector@3d2b92b5{SSL,[ssl, http/1.1]}{0.0.0.0:10000}",1
be7c0a22,Started @22881ms,1
7fd78aa1,Started ThriftHttpCLIService in https mode on port 10000 path=/cliservice/* with 5...500 worker threads,1
a90fba3b,Loading the root classloader,1
6b45de39,Starting sql repl <*>,7
975cab90,loadLibraries: Libraries failed to be installed: Set(),10
368e25dc,<*> finished to load,10
c2102708,Starting r repl ReplId-3593d-ebddd-8b23a-e,1
4092ff35,1. RDriverLocal.b6b4775f-de01-4706-97e6-5853537007e5: object created with for ReplId-3593d-ebddd-8b23a-e.,1
a50bc5a8,2. RDriverLocal.b6b4775f-de01-4706-97e6-5853537007e5: initializing ...,1
e43a7a5b,3. RDriverLocal.b6b4775f-de01-4706-97e6-5853537007e5: started RBackend thread on port 41274,1
eb63dba5,4. RDriverLocal.b6b4775f-de01-4706-97e6-5853537007e5: waiting for SparkR to be installed ...,1
642ab912,Starting python repl ReplId-8497b-f4c2d-af4d9,1
109b3335,Starting gateway server for repl ReplId-8497b-f4c2d-af4d9,1
71bc67d1,"resolved command to be run: List(virtualenv, /local_disk0/pythonVirtualEnvDirs/virtualEnv-ff80c1c3-b8f2-4aa9-a3d2-992aedee6f5b, --no-site-packages, -p, /databricks/python/bin/python, --no-setuptools, --no-wheel, --no-pip)",1
e147e61a,Starting scala repl ReplId-641e1-43796-385e1-8,1
60154ad1,Added result fetcher for <*>,13
8e3b1fd8,created python virtualenv: /local_disk0/pythonVirtualEnvDirs/virtualEnv-ff80c1c3-b8f2-4aa9-a3d2-992aedee6f5b,1
e79f3eaa,"resolved command to be run: List(/local_disk0/pythonVirtualEnvDirs/virtualEnv-ff80c1c3-b8f2-4aa9-a3d2-992aedee6f5b/bin/python, -c, from distutils.sysconfig import get_python_lib; print(get_python_lib()))",1
d066e11a,Registered signal handler for INT,1
2a3ccd9f,"resolved command to be run: List(/databricks/python/bin/python, -c, import sys; dirs=[p for p in sys.path if 'package' in p]; print(' '.join(dirs)))",1
957c2090,created sitecustomize.py at /local_disk0/pythonVirtualEnvDirs/virtualEnv-ff80c1c3-b8f2-4aa9-a3d2-992aedee6f5b/lib/python3.7/sitecustomize.py,1
89303877,Time spent to start virtualenv /local_disk0/pythonVirtualEnvDirs/virtualEnv-ff80c1c3-b8f2-4aa9-a3d2-992aedee6f5b is 1090,1
1bdee7df,"Python process builder: [/databricks/spark/python/pyspark/wrapped_python.py, root, /local_disk0/pythonVirtualEnvDirs/virtualEnv-ff80c1c3-b8f2-4aa9-a3d2-992aedee6f5b/bin/python, -u, /local_disk0/tmp/1582930072342-0/PythonShell.py, 43339, 0, 50000, 2177, 218164f3f65d4a4ca63276a38e458e45, 2.4.4, 0bece102c3a57c7e446912d4a03cdd4feaf1aacc0a97cdf63fb5412c44f02820]",1
9f15ff7c,"Cgroup isolation disabled, not placing python process in repl cgroup",1
9a561085,Setting LogicalPlanStats visitor to com.databricks.sql.optimizer.statsEstimation.DatabricksLogicalPlanStatsVisitor$,1
f59cda88,Set class prefix to: line49b319df9593406199cec71f0268458a,1
16caeedd,set ContextClassLoader,1
679bf9b9,initialized intp,1
9e9af40d,Initializing HiveMetastoreConnection version 0.13.0 using file:/databricks/hive/spark--maven-trees--spark_2.4--org.eclipse.jetty--jetty-security--org.eclipse.jetty__jetty-security__9.3.27.v20190418.jar:file:/databricks/hive/third_party--opencensus-shaded--com.google.code.gson__gson__2.8.2_shaded.jar:file:/databricks/hive/----scalapb_090--com.google.protobuf__protobuf-java-util__3.7.1_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.twitter--util-core_2.11--com.twitter__util-core_2.11__6.23.0.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.directory.server--apacheds-i18n--org.apache.directory.server__apacheds-i18n__2.0.0-M15.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--commons-collections--commons-collections--commons-collections__commons-collections__3.2.2.jar:file:/databricks/hive/daemon--data--client--client-spark_2.4_2.11_deploy.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.xerial.snappy--snappy-java--org.xerial.snappy__snappy-java__1.1.2.6.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.commons--commons-math3--org.apache.commons__commons-math3__3.4.1.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--commons-beanutils--commons-beanutils--commons-beanutils__commons-beanutils__1.9.4.jar:file:/databricks/hive/third_party--opencensus-shaded--io.opencensus__opencensus-exporter-trace-jaeger__0.22.1_shaded.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.fasterxml.jackson.core__jackson-annotations__2.7.0_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--com.esotericsoftware.minlog--minlog--com.esotericsoftware.minlog__minlog__1.2.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.microsoft.azure__azure-annotations__1.2.0_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--software.amazon.ion--ion-java--software.amazon.ion__ion-java__1.0.2.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--org.apache.httpcomponents__httpcore__4.4.4_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.databricks.scalapb--scalapb-runtime_2.11--com.databricks.scalapb__scalapb-runtime_2.11__0.4.15-9.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.htrace--htrace-core--org.apache.htrace__htrace-core__3.1.0-incubating.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.apache.ant--ant-launcher--org.apache.ant__ant-launcher__1.9.2.jar:file:/databricks/hive/third_party--azure--com.microsoft.azure__azure-keyvault-core__1.0.0_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.apache.zookeeper--zookeeper--org.apache.zookeeper__zookeeper__3.4.6.jar:file:/databricks/hive/third_party--jetty8-shaded-client--databricks-patched-jetty-http-jar_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.amazonaws--aws-java-sdk-kms--com.amazonaws__aws-java-sdk-kms__1.11.595.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive--hive-ant--org.spark-project.hive__hive-ant__0.13.1a.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.hadoop--hadoop-auth--org.apache.hadoop__hadoop-auth__2.7.3.jar:file:/databricks/hive/third_party--opencensus-shaded--commons-logging__commons-logging__1.2_shaded.jar:file:/databricks/hive/third_party--jackson--guava_only_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--info.ganglia.gmetric4j--gmetric4j--info.ganglia.gmetric4j__gmetric4j__1.0.7.jar:file:/databricks/hive/third_party--opencensus-shaded--io.opencensus__opencensus-impl-core__0.22.1_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.scala-lang.modules--scala-parser-combinators_2.11--org.scala-lang.modules__scala-parser-combinators_2.11__1.1.0.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--com.jolbox--bonecp--com.jolbox__bonecp__0.8.0.RELEASE.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.slf4j--slf4j-api--org.slf4j__slf4j-api__1.7.5.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--hadoop-azure-2.7.3-abfs-external-20180920_b33d810-spark_2.4_2.11_deploy_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.apache.derby--derby--org.apache.derby__derby__10.10.1.1.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--commons-codec--commons-codec--commons-codec__commons-codec__1.8.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.google.protobuf--protobuf-java--com.google.protobuf__protobuf-java__2.6.1.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--commons-codec--commons-codec--commons-codec__commons-codec__1.10.jar:file:/databricks/hive/----scalapb_090--org.codehaus.mojo__animal-sniffer-annotations__1.17_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--io.dropwizard.metrics--metrics-jetty9--io.dropwizard.metrics__metrics-jetty9__3.1.5.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.twitter--util-app_2.11--com.twitter__util-app_2.11__6.23.0.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--javax.xml.bind__jaxb-api__2.2.2_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--commons-cli--commons-cli--commons-cli__commons-cli__1.2.jar:file:/databricks/hive/----scalapb_090--io.perfmark__perfmark-api__0.16.0_shaded.jar:file:/databricks/hive/third_party--jetty8-shaded-client--jetty-jmx_shaded.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.google.inject__guice__3.0_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.jdbi--jdbi--org.jdbi__jdbi__2.63.1.jar:file:/databricks/hive/----scalapb_090--io.grpc__grpc-stub__1.21.0_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive--hive-jdbc--org.spark-project.hive__hive-jdbc__0.13.1a.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--commons-httpclient--commons-httpclient--commons-httpclient__commons-httpclient__3.1.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.amazonaws--aws-java-sdk-core--com.amazonaws__aws-java-sdk-core__1.11.595.jar:file:/databricks/hive/logging--log4j-mod--log4j-mod-spark_2.4_2.11_deploy.jar:file:/databricks/hive/third_party--opencensus-shaded--org.apache.thrift__libthrift__0.11.0_shaded.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.microsoft.azure__azure-keyvault-core__1.0.0_2.11_shaded_20180920_b33d810.jar:file:/databricks/hive/extern--acl--auth--auth-spark_2.4_2.11_deploy.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.datanucleus--datanucleus-rdbms--org.datanucleus__datanucleus-rdbms__3.2.9.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive--hive-metastore--org.spark-project.hive__hive-metastore__0.13.1a.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.httpcomponents--httpclient--org.apache.httpcomponents__httpclient__4.5.6.jar:file:/databricks/hive/third_party--azure--org.apache.commons__commons-lang3__3.4_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.datanucleus--datanucleus-core--org.datanucleus__datanucleus-core__3.2.10.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive.shims--hive-shims-0.23--org.spark-project.hive.shims__hive-shims-0.23__0.13.1a.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive--hive-common--org.spark-project.hive__hive-common__0.13.1a.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.scala-lang.modules--scala-xml_2.11--org.scala-lang.modules__scala-xml_2.11__1.0.5.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.antlr--stringtemplate--org.antlr__stringtemplate__3.2.1.jar:file:/databricks/hive/third_party--opencensus-shaded--io.opentracing__opentracing-api__0.31.0_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.google.guava--guava--com.google.guava__guava__15.0.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.scalatest--scalatest_2.11--org.scalatest__scalatest_2.11__3.0.3.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--commons-net--commons-net--commons-net__commons-net__3.1.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.eclipse.jetty--jetty-client--org.eclipse.jetty__jetty-client__9.3.27.v20190418.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.eclipse.jetty--jetty-servlets--org.eclipse.jetty__jetty-servlets__9.3.27.v20190418.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.fasterxml.jackson.core--jackson-databind--com.fasterxml.jackson.core__jackson-databind__2.6.7.1.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.apache.velocity--velocity--org.apache.velocity__velocity__1.5.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.objenesis--objenesis--org.objenesis__objenesis__1.2.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.squareup.okio__okio__1.8.0_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.codehaus.jackson--jackson-core-asl--org.codehaus.jackson__jackson-core-asl__1.9.13.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.apache.thrift--libthrift--org.apache.thrift__libthrift__0.9.2.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.apache.avro--avro--org.apache.avro__avro__1.8.2.jar:file:/databricks/hive/----scalapb_090--com.google.protobuf__protobuf-java__3.7.1_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.directory.api--api-asn1-api--org.apache.directory.api__api-asn1-api__1.0.0-M20.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.microsoft.rest__client-runtime__1.1.0_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.google.guava__guava__11.0.2_2.11_shaded_20180920_b33d810.jar:file:/databricks/hive/third_party--opencensus-shaded--com.lmax__disruptor__3.4.2_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.amazonaws--aws-java-sdk-sts--com.amazonaws__aws-java-sdk-sts__1.11.595.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--io.dropwizard.metrics--metrics-ganglia--io.dropwizard.metrics__metrics-ganglia__3.1.5.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--io.dropwizard.metrics--metrics-servlets--io.dropwizard.metrics__metrics-servlets__3.1.5.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.eclipse.jetty--jetty-http--org.eclipse.jetty__jetty-http__9.3.27.v20190418.jar:file:/databricks/hive/----scalapb_090--io.grpc__grpc-core__1.22.1_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.directory.server--apacheds-kerberos-codec--org.apache.directory.server__apacheds-kerberos-codec__2.0.0-M15.jar:file:/databricks/hive/s3commit--common--common-spark_2.4_2.11_deploy.jar:file:/databricks/hive/third_party--datalake--datalake-spark_2.4_2.11_deploy.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--io.dropwizard.metrics--metrics-jvm--io.dropwizard.metrics__metrics-jvm__3.1.5.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.eclipse.jetty--jetty-continuation--org.eclipse.jetty__jetty-continuation__9.3.27.v20190418.jar:file:/databricks/hive/third_party--opencensus-shaded--com.google.j2objc__j2objc-annotations__1.1_shaded.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--org.apache.httpcomponents__httpcore__4.4.4_2.11_shaded_20180920_b33d810.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive.shims--hive-shims-common--org.spark-project.hive.shims__hive-shims-common__0.13.1a.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.apache.ant--ant--org.apache.ant__ant__1.9.2.jar:file:/databricks/hive/third_party--jackson--paranamer_only_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive.shims--hive-shims-0.20--org.spark-project.hive.shims__hive-shims-0.20__0.13.1a.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.springframework--spring-core--org.springframework__spring-core__4.1.4.RELEASE.jar:file:/databricks/hive/third_party--prometheus-client--simpleclient-spark_2.4_2.11_deploy.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.fasterxml.jackson.core__jackson-core__2.7.2_2.11_shaded_20180920_b33d810.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--io.dropwizard.metrics--metrics-json--io.dropwizard.metrics__metrics-json__3.1.5.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.jboss.logging--jboss-logging--org.jboss.logging__jboss-logging__3.1.3.GA.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.squareup.okhttp3__logging-interceptor__3.3.1_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/common--client--client-spark_2.4_2.11_deploy.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--javax.jdo--jdo-api--javax.jdo__jdo-api__3.0.1.jar:file:/databricks/hive/----scalapb_090--com.lihaoyi__sourcecode_2.11__0.1.6_shaded.jar:file:/databricks/hive/----scalapb_090--io.grpc__grpc-context__1.22.1_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.trueaccord.lenses--lenses_2.11--com.trueaccord.lenses__lenses_2.11__0.3.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.curator--curator-client--org.apache.curator__curator-client__2.7.1.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.eclipse.jetty--jetty-proxy--org.eclipse.jetty__jetty-proxy__9.3.27.v20190418.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--com.esotericsoftware.kryo--kryo--com.esotericsoftware.kryo__kryo__2.21.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.google.guava__guava__16.0_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.curator--curator-recipes--org.apache.curator__curator-recipes__2.7.1.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.hadoop--hadoop-annotations--org.apache.hadoop__hadoop-annotations__2.7.3.jar:file:/databricks/hive/third_party--opencensus-shaded--io.grpc__grpc-context__1.19.0_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--javax.el--javax.el-api--javax.el__javax.el-api__2.2.4.jar:file:/databricks/hive/third_party--opencensus-shaded--com.squareup.okhttp3__okhttp__3.9.0_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.directory.api--api-util--org.apache.directory.api__api-util__1.0.0-M20.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.apache.commons--commons-lang3--org.apache.commons__commons-lang3__3.4.jar:file:/databricks/hive/third_party--azure--com.microsoft.azure__azure-storage__7.0.0_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.codehaus.jackson--jackson-core-asl--org.codehaus.jackson__jackson-core-asl__1.9.13.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--commons-httpclient--commons-httpclient--commons-httpclient__commons-httpclient__3.1.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.curator--curator-framework--org.apache.curator__curator-framework__2.7.1.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.protobuf--protobuf-java--org.spark-project.protobuf__protobuf-java__2.5.0-spark.jar:file:/databricks/hive/third_party--jetty-client--jetty-util_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.antlr--antlr-runtime--org.antlr__antlr-runtime__3.4.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--commons-lang--commons-lang--commons-lang__commons-lang__2.6.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--io.dropwizard.metrics--metrics-log4j--io.dropwizard.metrics__metrics-log4j__3.1.5.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--io.netty--netty--io.netty__netty__3.9.9.Final.jar:file:/databricks/hive/third_party--opencensus-shaded--com.google.errorprone__error_prone_annotations__2.1.3_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.slf4j--slf4j-api--org.slf4j__slf4j-api__1.7.16.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--org.apache.htrace__htrace-core__3.1.0-incubating_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--com.googlecode.javaewah--JavaEWAH--com.googlecode.javaewah__JavaEWAH__0.3.2.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--log4j--log4j--log4j__log4j__1.2.17.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--javax.xml.stream__stax-api__1.0-2_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/third_party--opencensus-shaded--io.jaegertracing__jaeger-tracerresolver__0.33.1_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.eclipse.jetty--jetty-io--org.eclipse.jetty__jetty-io__9.3.27.v20190418.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.slf4j--slf4j-log4j12--org.slf4j__slf4j-log4j12__1.7.16.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.iq80.snappy--snappy--org.iq80.snappy__snappy__0.2.jar:file:/databricks/hive/third_party--opencensus-shaded--org.apache.httpcomponents__httpcore__4.4.1_shaded.jar:file:/databricks/hive/----scalapb_090--com.lihaoyi__fastparse_2.11__2.1.2_shaded.jar:file:/databricks/hive/third_party--jetty8-shaded-client--jetty-util_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.codehaus.jackson--jackson-mapper-asl--org.codehaus.jackson__jackson-mapper-asl__1.9.13.jar:file:/databricks/hive/----scalapb_090--io.opencensus__opencensus-contrib-grpc-metrics__0.21.0_shaded.jar:file:/databricks/hive/third_party--opencensus-shaded--io.jaegertracing__jaeger-client__0.33.1_shaded.jar:file:/databricks/hive/third_party--opencensus-shaded--io.opentracing.contrib__opentracing-tracerresolver__0.1.5_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.tukaani--xz--org.tukaani__xz__1.5.jar:file:/databricks/hive/third_party--opencensus-shaded--com.squareup.okio__okio__1.13.0_shaded.jar:file:/databricks/hive/----jackson_databind_shaded--libjackson-databind.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.apache.httpcomponents--httpcore--org.apache.httpcomponents__httpcore__4.4.1.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.eclipse.jetty--jetty-servlet--org.eclipse.jetty__jetty-servlet__9.3.27.v20190418.jar:file:/databricks/hive/----scalapb_090--io.grpc__grpc-protobuf-lite__1.21.0_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.databricks.scalapb--compilerplugin_2.11--com.databricks.scalapb__compilerplugin_2.11__0.4.15-9.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.typesafe.scala-logging--scala-logging-slf4j_2.11--com.typesafe.scala-logging__scala-logging-slf4j_2.11__2.1.2.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.google.code.findbugs__jsr305__1.3.9_2.11_shaded_20180920_b33d810.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--io.netty--netty-all--io.netty__netty-all__4.1.42.Final.jar:file:/databricks/hive/third_party--opencensus-shaded--io.jaegertracing__jaeger-thrift__0.33.1_shaded.jar:file:/databricks/hive/----scalapb_090--com.google.api.grpc__proto-google-common-protos__1.12.0_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.amazonaws--aws-java-sdk-s3--com.amazonaws__aws-java-sdk-s3__1.11.595.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.fasterxml.jackson.core--jackson-core--com.fasterxml.jackson.core__jackson-core__2.6.7.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.apache.httpcomponents--httpclient--org.apache.httpcomponents__httpclient__4.4.1.jar:file:/databricks/hive/third_party--opencensus-shaded--org.apache.httpcomponents__httpclient__4.4.1_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.xerial.snappy--snappy-java--org.xerial.snappy__snappy-java__1.1.7.3.jar:file:/databricks/hive/daemon--data--client--conf--conf-spark_2.4_2.11_deploy.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--commons-digester--commons-digester--commons-digester__commons-digester__1.8.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--com.thoughtworks.paranamer--paranamer--com.thoughtworks.paranamer__paranamer__2.8.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.apache.thrift--libfb303--org.apache.thrift__libfb303__0.9.0.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--log4j--apache-log4j-extras--log4j__apache-log4j-extras__1.2.17.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--io.dropwizard.metrics--metrics-core--io.dropwizard.metrics__metrics-core__3.1.5.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.amazonaws--jmespath-java--com.amazonaws__jmespath-java__1.11.595.jar:file:/databricks/hive/third_party--jackson--jackson-module-scala-shaded_2.11_deploy.jar:file:/databricks/hive/third_party--opencensus-shaded--org.codehaus.mojo__animal-sniffer-annotations__1.14_shaded.jar:file:/databricks/hive/----scalapb_090--runtime-unshaded-jetty9-hadoop1_2.11_deploy_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.twitter--util-jvm_2.11--com.twitter__util-jvm_2.11__6.23.0.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.antlr--ST4--org.antlr__ST4__4.0.4.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--joda-time--joda-time--joda-time__joda-time__2.9.3.jar:file:/databricks/hive/third_party--jetty-client--jetty-io_shaded.jar:file:/databricks/hive/----scalapb_090--com.google.errorprone__error_prone_annotations__2.3.2_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.codehaus.groovy--groovy-all--org.codehaus.groovy__groovy-all__2.1.6.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--org.apache.httpcomponents__httpclient__4.5.2_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--javax.inject__javax.inject__1_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/s3commit--client--client-spark_2.4_2.11_deploy.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.apache.commons--commons-compress--org.apache.commons__commons-compress__1.9.jar:file:/databricks/hive/common--credentials--credentials-spark_2.4_2.11_deploy.jar:file:/databricks/hive/third_party--opencensus-shaded--io.opentracing__opentracing-noop__0.31.0_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--com.esotericsoftware.reflectasm--reflectasm-shaded--com.esotericsoftware.reflectasm__reflectasm-shaded__1.07.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--commons-logging--commons-logging--commons-logging__commons-logging__1.1.3.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--jline--jline--jline__jline__0.9.94.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.slf4j--slf4j-log4j12--org.slf4j__slf4j-log4j12__1.7.5.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--com.twitter--parquet-hadoop-bundle--com.twitter__parquet-hadoop-bundle__1.3.2.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.typesafe.scala-logging--scala-logging-api_2.11--com.typesafe.scala-logging__scala-logging-api_2.11__2.1.2.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.microsoft.azure--azure-data-lake-store-sdk--com.microsoft.azure__azure-data-lake-store-sdk__2.2.8.jar:file:/databricks/hive/jsonutil--jsonutil-spark_2.4_2.11_deploy.jar:file:/databricks/hive/third_party--prometheus-client--simpleclient-jetty9-hadoop1_2.11_deploy.jar:file:/databricks/hive/third_party--opencensus-shaded--com.google.guava__guava__26.0-android_shaded.jar:file:/databricks/hive/extern--extern-spark_2.4_2.11_deploy.jar:file:/databricks/hive/dbfs--utils--dbfs-utils-spark_2.4_2.11_deploy.jar:file:/databricks/hive/daemon--data--data-common--data-common-spark_2.4_2.11_deploy.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive--hive-service--org.spark-project.hive__hive-service__0.13.1a.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--commons-cli--commons-cli--commons-cli__commons-cli__1.2.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--net.sf.jpam--jpam--net.sf.jpam__jpam__1.1.jar:file:/databricks/hive/----scalapb_090--com.google.android__annotations__4.1.1.4_shaded.jar:file:/databricks/hive/third_party--prometheus-client--simpleclient_dropwizard-spark_2.4_2.11_deploy.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.fasterxml.jackson.datatype__jackson-datatype-joda__2.7.2_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.hibernate--hibernate-validator--org.hibernate__hibernate-validator__5.1.1.Final.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--junit--junit--junit__junit__3.8.1.jar:file:/databricks/hive/----scalapb_090--com.google.code.gson__gson__2.7_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--oro--oro--oro__oro__2.0.8.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--aopalliance__aopalliance__1.0_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/third_party--opencensus-shaded--io.opencensus__opencensus-impl__0.22.1_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.scala-lang--scala-library_2.11--org.scala-lang__scala-library__2.11.12.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.eclipse.jetty--jetty-util--org.eclipse.jetty__jetty-util__9.3.27.v20190418.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--javax.activation__activation__1.1_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/third_party--opencensus-shaded--io.opencensus__opencensus-api__0.22.1_shaded.jar:file:/databricks/hive/third_party--jetty-client--jetty-client_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.avro--avro--org.apache.avro__avro__1.8.2.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--javolution--javolution--javolution__javolution__5.5.1.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.squareup.retrofit2__adapter-rxjava__2.1.0_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--stax--stax-api--stax__stax-api__1.0.1.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.tukaani--xz--org.tukaani__xz__1.5.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.acplt--oncrpc--org.acplt__oncrpc__1.0.7.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--commons-logging__commons-logging__1.2_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive--hive-exec--org.spark-project.hive__hive-exec__0.13.1a.jar:file:/databricks/hive/----scalapb_090--com.fasterxml.jackson.core__jackson-core__2.9.9_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive.shims--hive-shims-0.20S--org.spark-project.hive.shims__hive-shims-0.20S__0.13.1a.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--commons-io--commons-io--commons-io__commons-io__2.4.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--io.reactivex__rxjava__1.2.4_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/third_party--opencensus-shaded--io.jaegertracing__jaeger-core__0.33.1_shaded.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.fasterxml.jackson.core__jackson-core__2.7.2_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.databricks--jets3t--com.databricks__jets3t__0.7.1-0.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--org.apache.httpcomponents__httpclient__4.5.2_2.11_shaded_20180920_b33d810.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--commons-logging--commons-logging--commons-logging__commons-logging__1.1.3.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.httpcomponents--httpcore--org.apache.httpcomponents__httpcore__4.4.10.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--javax.transaction--jta--javax.transaction__jta__1.1.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive--hive-beeline--org.spark-project.hive__hive-beeline__0.13.1a.jar:file:/databricks/hive/third_party--jetty-client--jetty-http_shaded.jar:file:/databricks/hive/----scalapb_090--io.grpc__grpc-netty__1.22.1_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.datanucleus--datanucleus-api-jdo--org.datanucleus__datanucleus-api-jdo__3.2.6.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.squareup.okhttp3__okhttp__3.3.1_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/third_party--opencensus-shaded--commons-codec__commons-codec__1.9_shaded.jar:file:/databricks/hive/s3--s3-spark_2.4_2.11_deploy.jar:file:/databricks/hive/----scalapb_090--io.opencensus__opencensus-api__0.21.0_shaded.jar:file:/databricks/hive/----jackson_annotations_shaded--libjackson-annotations.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.typesafe--config--com.typesafe__config__1.2.1.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--io.netty--netty--io.netty__netty__3.8.0.Final.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.hadoop--hadoop-common--org.apache.hadoop__hadoop-common__2.7.3.jar:file:/databricks/hive/third_party--opencensus-shaded--org.checkerframework__checker-compat-qual__2.5.2_shaded.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.squareup.retrofit2__retrofit__2.1.0_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--antlr--antlr--antlr__antlr__2.7.7.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.springframework--spring-test--org.springframework__spring-test__4.1.4.RELEASE.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.fasterxml.jackson.core__jackson-databind__2.7.2_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/common--hadoop--hadoop-spark_2.4_2.11_deploy.jar:file:/databricks/hive/common--path--path-spark_2.4_2.11_deploy.jar:file:/databricks/hive/third_party--jetty8-shaded-client--jetty-io_shaded.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.microsoft.azure__azure-storage__7.0.0_2.11_shaded_20180920_b33d810.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--javax.servlet.jsp--jsp-api--javax.servlet.jsp__jsp-api__2.1.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.scala-lang--scala-reflect_2.11--org.scala-lang__scala-reflect__2.11.12.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--commons-codec__commons-codec__1.9_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--commons-logging__commons-logging__1.2_2.11_shaded_20180920_b33d810.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.squareup.retrofit2__converter-jackson__2.1.0_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.google.code.findbugs--jsr305--com.google.code.findbugs__jsr305__2.0.1.jar:file:/databricks/hive/third_party--opencensus-shaded--com.google.code.findbugs__jsr305__3.0.2_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--io.dropwizard.metrics--metrics-healthchecks--io.dropwizard.metrics__metrics-healthchecks__3.1.5.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--hadoop-azure-2.7.3-abfs-external-20180625_3682417-spark_2.4_2.11_deploy_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive.shims--hive-shims-common-secure--org.spark-project.hive.shims__hive-shims-common-secure__0.13.1a.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--commons-configuration--commons-configuration--commons-configuration__commons-configuration__1.6.jar:file:/databricks/hive/third_party--jetty8-shaded-client--databricks-patched-jetty-client-jar_shaded.jar:file:/databricks/hive/common--lazy--lazy-spark_2.4_2.11_deploy.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.squareup.okhttp3__okhttp-urlconnection__3.3.1_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--log4j--log4j--log4j__log4j__1.2.17.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.eclipse.jetty--jetty-server--org.eclipse.jetty__jetty-server__9.3.27.v20190418.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.fasterxml.jackson.dataformat--jackson-dataformat-cbor--com.fasterxml.jackson.dataformat__jackson-dataformat-cbor__2.6.7.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.json--json--org.json__json__20090211.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.google.code.gson--gson--com.google.code.gson__gson__2.2.4.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--commons-io--commons-io--commons-io__commons-io__2.5.jar:file:/databricks/hive/third_party--opencensus-shaded--io.opentracing__opentracing-util__0.31.0_shaded.jar:file:/databricks/hive/api-base--api-base-spark_2.4_2.11_deploy.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--io.netty__netty-all__4.0.52.Final_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--xmlenc--xmlenc--xmlenc__xmlenc__0.52.jar:file:/databricks/hive/api-base--api-base_java-spark_2.4_2.11_deploy.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive--hive-shims--org.spark-project.hive__hive-shims__0.13.1a.jar:file:/databricks/hive/third_party--opencensus-shaded--io.opencensus__opencensus-exporter-trace-util__0.22.1_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--commons-lang--commons-lang--commons-lang__commons-lang__2.6.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--commons-codec__commons-codec__1.9_2.11_shaded_20180920_b33d810.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive--hive-cli--org.spark-project.hive__hive-cli__0.13.1a.jar:file:/databricks/hive/third_party--azure--com.fasterxml.jackson.core__jackson-core__2.7.2_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--org.spark-project.hive--hive-serde--org.spark-project.hive__hive-serde__0.13.1a.jar:file:/databricks/hive/----scalapb_090--io.grpc__grpc-protobuf__1.21.0_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--javax.validation--validation-api--javax.validation__validation-api__1.1.0.Final.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.commons--commons-compress--org.apache.commons__commons-compress__1.8.1.jar:file:/databricks/hive/spark--maven-trees--spark_1.4_hive_0.13--commons-collections--commons-collections--commons-collections__commons-collections__3.2.2.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.apache.zookeeper--zookeeper--org.apache.zookeeper__zookeeper__3.4.6.jar:file:/databricks/hive/third_party--jackson--jsr305_only_shaded.jar:file:/databricks/hive/extern--libaws-regions.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.joda--joda-convert--org.joda__joda-convert__1.7.jar:file:/databricks/hive/----jackson_datatype_joda_shaded--libjackson-datatype-joda.jar:file:/databricks/hive/----scalapb_090--com.google.guava__guava__20.0_shaded.jar:file:/databricks/hive/----scalapb_090--io.grpc__grpc-api__1.22.1_shaded.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--javax.servlet--javax.servlet-api--javax.servlet__javax.servlet-api__3.1.0.jar:file:/databricks/hive/common--jetty--client--client-spark_2.4_2.11_deploy.jar:file:/databricks/hive/----jackson_core_shaded--libjackson-core.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--org.scalactic--scalactic_2.11--org.scalactic__scalactic_2.11__3.0.3.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.fasterxml--classmate--com.fasterxml__classmate__1.0.0.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.thoughtworks.paranamer--paranamer--com.thoughtworks.paranamer__paranamer__2.8.jar:file:/databricks/hive/spark--maven-trees--spark_2.4--com.fasterxml.jackson.core--jackson-annotations--com.fasterxml.jackson.core__jackson-annotations__2.6.7.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--joda-time__joda-time__2.4_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/third_party--hadoop-azure-2.7.3-abfs--com.sun.xml.bind__jaxb-impl__2.2.3-1_2.11_shaded_20180625_3682417.jar:file:/databricks/hive/bonecp-configs.jar,1
f95d0c04,"Process of event SparkListenerSQLExecutionStart(0,show databases,org.apache.spark.sql.SQLContext.sql(SQLContext.scala:716)",1
95af587e,PythonDriver[ReplId-8497b-f4c2d-af4d9](stateStr) Set Python Interp in JVM for ReplId-8497b-f4c2d-af4d9,1
4bb9da49,No Tez session required at this point. hive.execution.engine=mr.,1
cc60c8fa,0: get_databases: *,2
c205b170,ugi=root ip=unknown-ip-addr cmd=get_databases: *,2
dd0b989b,"Process of event SparkListenerSQLUsageLogging(0,1582930082300,CallSite(sql at SQLDriverLocal.scala:88,org.apache.spark.sql.SQLContext.sql(SQLContext.scala:716)",1
52999028,Execution ID: <*> Total Executor Run Time: 0,24
67696ad5,Code generated in <*> ms,12
0d9ed607,Removed result fetcher for <*>,12
2110a61b,0: get_database: global_temp,1
12014f88,ugi=root ip=unknown-ip-addr cmd=get_database: global_temp,1
9abbc502,NoSuchObjectException(message:There is no database named global_temp),1
9ab6297d,0: get_table : db=default <*>,8
3cb90984,ugi=root ip=unknown-ip-addr cmd=get_table : db=default <*>,8
8ad03cda,SparkR installation completed.,1
01555867,5. RDriverLocal.b6b4775f-de01-4706-97e6-5853537007e5: launching R process ...,1
ec482961,"6. RDriverLocal.b6b4775f-de01-4706-97e6-5853537007e5: cgroup isolation disabled, not placing R process in REPL cgroup.",1
00a15d24,7. RDriverLocal.b6b4775f-de01-4706-97e6-5853537007e5: starting R process on port 1100 (attempt 1) ...,1
09862f36,8. RDriverLocal.b6b4775f-de01-4706-97e6-5853537007e5: setting up BufferedStreamThread with bufferSize: 100.,1
37511901,9. RDriverLocal.b6b4775f-de01-4706-97e6-5853537007e5: R process started with RServe listening on port 1100.,1
6a8ae455,10. RDriverLocal.b6b4775f-de01-4706-97e6-5853537007e5: starting interpreter to talk to R process ...,1
3794d0ab,Using an existing SparkContext; some configuration may not take effect.,1
3056bd2b,11. RDriverLocal.b6b4775f-de01-4706-97e6-5853537007e5: R interpretter is connected.,1
a8026567,Cleaned accumulator <*> (name: number of output rows),8
789df238,DBFS health check ok,2
cf605cef,1: get_database: default,2
5d8b1e0a,Metastore health check ok,2
6647097a,"DbfsOutputStream closed, reporting metrics.",1
